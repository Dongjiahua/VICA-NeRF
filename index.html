<!DOCTYPE html>
<html>

<head>

  <title>ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance
              Fields</h1>
            <h4 class="title is-4">Neurips 2023</h4>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a>Jiahua Dong</a>,</span>
              <span class="author-block">
                <a href="https://yxw.web.illinois.edu/">Yu-Xiong Wang</a>
              </span>

            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">University of Illinois Urbana-Champaign</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/pdf?id=Pk49a9snPe"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>





                <!--               <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->





                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Dongjiahua/VICA-NeRF"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/demo_video_without_submission_info_AdobeExpress.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Our MuvieNeRF compared with conventional discriminative multi-task learning method.
      </h2>
    </div>
  </div>
</section> -->



  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We introduce ViCA-NeRF, a view-consistency-aware method for 3D editing with
              text instructions. In addition to the implicit NeRF modeling, our key insight
              is to exploit two sources of regularization that explicitly propagate the editing
              information across different views, thus ensuring multi-view consistency. As
              geometric regularization, we leverage the depth information derived from the
              NeRF model to establish image correspondence between different views. As
              learned regularization, we align the latent codes in the 2D diffusion model between
              edited and unedited images, enabling us to edit key views and propagate the update
              to the whole scene. Incorporating these two regularizations, our ViCA-NeRF
              framework consists of two stages. In the initial stage, we blend edits from different
              views to create a preliminary 3D edit. This is followed by a second stage of NeRF
              training that is dedicated to further refining the sceneâ€™s appearance. Experiments
              demonstrate that ViCA-NeRF provides more flexible, efficient(3 times faster)
              editing with higher levels of consistency and details, compared with the state of the
              art.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
      <!--/ Paper video. -->
    </div>

  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column column is-full-width">
          <h2 class="title is-3">ViCA-NeRF Pipeline</h2>
          <div class="content has-text-justified">
            ViCA-NeRF is an efficient, controllable NeRF editing pipeline which can edit 3D scenes with text
            instructions.
            It shows better generalizability for various text instructions
            <div class="paragraph">
              <p>
                ViCA-NeRF leverages two sources of regularization to propagate editing information
              <ol>
                <li>Edit key views through Instruct-Pix2Pix, extract the depth.</li>
                <li>Project edited key views to other views using depth.</li>
                <li>Further refine images through a blending module .</li>
                <li>Train NeRF with the updated dataset.</li>
              </ol>
              </p>
            </div>
            <div align="center"><img src="./static/images/new_pip.png" alt="" width=100% /></span></div>

          </div>
        </div>
      </div>
      <!--   <div class="container is-max-desktop"> -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h3 class="title is-4">How ViCA-NeRF Edits 3D Scenes</h3>

          <div class="column interpolation-video-column">
            <video id="link2" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/vica_ani.mp4" type="video/mp4">
            </video>
          </div>
          <br />
        </div>
      </div>

      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <!-- Animation. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Early Control from 2D to 3D</h2>

          <div class="columns is-vcentered interpolation-panel">
            <div class="column is-3 has-text-centered">
              <img src="./static/images/link1.png" class="interpolation-image" height="80%"
                alt="Interpolate start reference image." />
              <p class="is-bold">Edited Key View</p>
            </div>
            <div class="column interpolation-video-column">
              <video id="link1" autoplay muted loop playsinline>
                <source src="./static/videos/new_link_ours.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/images/link2.png" class="interpolation-image" height="80%"
                alt="Interpolation end reference image." />
              <p class="is-bold">Edited Key View</p>
            </div>
            <div class="column interpolation-video-column">
              <video id="link2" autoplay muted loop playsinline>
                <source src="./static/videos/new_link_ours_2.mp4" type="video/mp4">
              </video>
            </div>
            
            <br />
            <!--/ Interpolating. -->

          </div>
        </div>
      </div>

        <!-- <div class="columns is-centered">
        <div class="column is-full-width">
          <h3 class="title is-4">Direct Dataset modification</h3>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column is-3 has-text-centered">
              <img src="./static/images/link1.png" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p class="is-bold">Edited key view</p>
            </div>

          </div>
          <br />
        </div>
      </div> -->

        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Qualatitive results</h2>
            <div class="column interpolation-video-column">
              <video id="link2" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/nerfart.mp4" type="video/mp4">
              </video>
            </div>
            <br />
          </div>
        </div>

        <!--/ Animation. -->
        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experimental Results</h2>
        <div class="content has-text-justified">
        

          <h3 class="title is-4">Comparison with Baselines</h3>
        <div class="content has-text-justified">
          <p>
            We conduct experiments on two datasets: <a href="https://arxiv.org/abs/1906.05797">Replica</a> and <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/McCormac_SceneNet_RGB-D_Can_ICCV_2017_paper.pdf">SceneNet RGB-D</a>. 
            Five tasks beyond RGB are chosen: surface normal prediction (SN), 
            shading prediction (SH), edge detection (ED), keypoint detection (KP) and semantic label prediction (SL). Baseline methods include the state-of-the-art discriminative model
            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870506.pdf">InvPT</a>, single-task NeRF model
            <a href="https://shuaifengzhi.com/Semantic-NeRF/">Semantic-NeRF</a> and naive multi-task NeRF model 
            <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Beyond_RGB_Scene-Property_Synthesis_With_Neural_Radiance_Fields_WACV_2023_paper.pdf">SS-NeRF</a>.
          </p>
          
          <p>
            Qualitative comparison on Replica dataset:
          </p>
        
          <div align="center"><img src="./static/images/replica.png" alt="" width=85% /></span></div>
          <p>
            Qualitative comparison on SceneNet RGB-D dataset:
          </p>
          <div align="center"><img src="./static/images/scenenet.png" alt="" width=70% /></span></div>
        </div>

          <h3 class="title is-4">Out-of-distribution Generalization</h3>
        <div class="content has-text-justified">
          <p>
            The knowledge of multi-task synergy learned during training benefits generalization on out-of-distribution datasets, boosting the performance of 
            novel view RGB synthesis, even when 2D task signals from input views are unavailable.
          </p>
          
          <p>
            Four out-of-distribution datasets <a href="http://www.scan-net.org/">ScanNet</a>, 
            <a href="https://theairlab.org/tartanair-dataset/">TartanAir</a>, 
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yao_BlendedMVS_A_Large-Scale_Dataset_for_Generalized_Multi-View_Stereo_Networks_CVPR_2020_paper.pdf">BlendedMVS</a>, 
            <a href="https://bmild.github.io/llff/">LLFF</a> (from left to right, top to bottom) are evaluated:
          </p>
          <div align="center"><img src="./static/images/ood.png" alt="" width=85% /></span></div>
        </div> -->
        <!--         <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div> -->


      </div>
    </div>
    </div>
    <!--/ Paper video. -->
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{vicanerf2023,
      author = {Dong, Jiahua and Wang, Yu-Xiong},
      title = {ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields},
      booktitle = {NeurIPS},
      year = {2023},
     } 
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://zsh2000.github.io/mtvs.github.io/static/paper/mtvs.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/zsh2000/" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              The website template is borrowed from the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website. Thanks the authors of Nerfies of sharing this great template!
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>